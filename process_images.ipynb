{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "contained-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_first_image():\n",
    "    files = Path('/mnt/data/car_auction_data/').glob(\"backup*\")\n",
    "    files = sorted(files)\n",
    "    for file in files:\n",
    "        print(str(file))\n",
    "        data = pkl.load(open(file,\"rb\"))\n",
    "        for row in data:\n",
    "            if len(row['images']) > 0:\n",
    "                im = tf.image.decode_jpeg(row['images'][0])\n",
    "                im = tf.image.convert_image_dtype(im, tf.float32)\n",
    "                im = tf.image.resize(im, [128, 128])\n",
    "                # For later models where we might want to process everything at once\n",
    "                desc =  tf.constant(row['description'], dtype=tf.string)\n",
    "                yield im, tf.constant(row['price_float'], dtype=tf.float32)\n",
    "\n",
    "            \n",
    "# import itertools\n",
    "\n",
    "# for image, label, desc in itertools.islice(retrieve_first_image(),3):\n",
    "# #     image, label, desc = next(retrieve_first_image())\n",
    "#     plt.figure()\n",
    "#     plt.imshow(image.numpy())\n",
    "#     plt.title(label.numpy())\n",
    "#     print(desc.numpy(), image.shape, label.shape, desc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "working-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.from_generator(retrieve_first_image, \n",
    "                                        output_types=(tf.float32, tf.float32), \n",
    "                                        output_shapes=((128,128,3),())\n",
    "                                        )\n",
    "# tfds.benchmark(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "documentary-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, label in images.take(3):\n",
    "#     plt.figure()\n",
    "#     plt.imshow(image.numpy())\n",
    "#     plt.title(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "partial-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.shuffle(1000).batch(50, drop_remainder=True)\n",
    "\n",
    "model = K.Sequential([\n",
    "    K.Input(shape=(128,128,3)),\n",
    "    K.layers.Conv2D(16, (3,3), padding=\"SAME\"),\n",
    "    K.layers.BatchNormalization(),\n",
    "    K.layers.Conv2D(16, (3,3), padding=\"SAME\"),\n",
    "#     K.layers.BatchNormalization(),\n",
    "#     K.layers.MaxPool2D((2,2)),\n",
    "#     K.layers.Conv2D(16, (3,3), padding=\"valid\"),\n",
    "#     K.layers.BatchNormalization(),\n",
    "#     K.layers.Conv2D(16, (3,3), padding=\"valid\"),\n",
    "#     K.layers.BatchNormalization(),\n",
    "#     K.layers.MaxPool2D((2,2)),\n",
    "    K.layers.Flatten(),\n",
    "    K.layers.Dense(64, activation=\"relu\"),\n",
    "    K.layers.Dense(32, activation=\"relu\"),\n",
    "    K.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floppy-heavy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/car_auction_data/backup_Convertible_0-1000_0_110.pickle\n",
      "/mnt/data/car_auction_data/backup_Convertible_1000-2000_0_500.pickle\n",
      "/mnt/data/car_auction_data/backup_Convertible_1000-2000_500_539.pickle\n",
      "/mnt/data/car_auction_data/backup_Convertible_10000-11000_0_462.pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=44806388.0>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_step(next(iter(images.take(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-america",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "/mnt/data/car_auction_data/backup_Convertible_0-1000_0_110.pickle\n",
      "/mnt/data/car_auction_data/backup_Convertible_1000-2000_0_500.pickle\n",
      "/mnt/data/car_auction_data/backup_Convertible_1000-2000_500_539.pickle\n",
      "/mnt/data/car_auction_data/backup_Convertible_10000-11000_0_462.pickle\n",
      "      1/Unknown - 0s 4ms/step - loss: 40477008.0000/mnt/data/car_auction_data/backup_Convertible_11000-12000_0_485.pickle\n",
      "     10/Unknown - 24s 2s/step - loss: 35368884.0000/mnt/data/car_auction_data/backup_Convertible_2000-3000_0_490.pickle\n"
     ]
    }
   ],
   "source": [
    "model.fit(images, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in images.take(1):\n",
    "    fig = plt.figure(figsize=(8,32))\n",
    "    axs = fig.subplots(25,2)\n",
    "    ims = batch[0].numpy()\n",
    "    prices = batch[1].numpy()\n",
    "    i = 0\n",
    "    for row in axs:\n",
    "        for ax in row:\n",
    "            ax.imshow(ims[i])\n",
    "            ax.set_title(prices[i])\n",
    "            i += 1\n",
    "    fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "prices = []\n",
    "\n",
    "for ims, truth in images:\n",
    "    preds.extend(model.predict(ims)[:,0])\n",
    "    prices.extend(truth.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0,1000)\n",
    "ax.set_ylim(0,1000)\n",
    "# ax.hist2d(prices, preds, bins=20)\n",
    "ax.plot(prices, prices, color=\"black\")\n",
    "ax.scatter(prices,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-conditions",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
